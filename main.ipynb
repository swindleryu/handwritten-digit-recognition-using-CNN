{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GR 5293 FINAL PROJECT REPORT \n",
    "Implement a handwritten digit recognition classifier using CNN \n",
    "\n",
    "Team Name: TBD\n",
    "\n",
    "Zonghao Li : zl2613\n",
    "\n",
    "Wenting Yu : wy2294\n",
    "\n",
    "Guyu Zhang : gz2263\n",
    "\n",
    "Date: 2018/05/06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code for the first part was cited from (https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.2678 - acc: 0.9182 - val_loss: 0.0593 - val_acc: 0.9817\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 80s 1ms/step - loss: 0.0901 - acc: 0.9730 - val_loss: 0.0438 - val_acc: 0.9857\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 81s 1ms/step - loss: 0.0640 - acc: 0.9809 - val_loss: 0.0342 - val_acc: 0.9881\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0536 - acc: 0.9838 - val_loss: 0.0339 - val_acc: 0.9891\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0461 - acc: 0.9859 - val_loss: 0.0289 - val_acc: 0.9912\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0414 - acc: 0.9875 - val_loss: 0.0285 - val_acc: 0.9902\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 81s 1ms/step - loss: 0.0372 - acc: 0.9886 - val_loss: 0.0288 - val_acc: 0.9904\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0329 - acc: 0.9904 - val_loss: 0.0279 - val_acc: 0.9916\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0307 - acc: 0.9905 - val_loss: 0.0281 - val_acc: 0.9913\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.0290 - acc: 0.9913 - val_loss: 0.0271 - val_acc: 0.9912\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0264 - acc: 0.9921 - val_loss: 0.0244 - val_acc: 0.9923\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0263 - acc: 0.9915 - val_loss: 0.0253 - val_acc: 0.9922\n",
      "Test loss: 0.025254336873247667\n",
      "Test accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model after fixing the bug\n",
    "\n",
    "#### Extra Credit Part 1:\n",
    "  - Bug: model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,verbose=1,  validation_data=(x_test, y_test))\n",
    "  - Correction: model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs, verbose=1, validation_split=1/5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 66s 1ms/step - loss: 0.2987 - acc: 0.9067 - val_loss: 0.0681 - val_acc: 0.9799\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 66s 1ms/step - loss: 0.0964 - acc: 0.9712 - val_loss: 0.0507 - val_acc: 0.9853\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 65s 1ms/step - loss: 0.0697 - acc: 0.9790 - val_loss: 0.0456 - val_acc: 0.9876\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 65s 1ms/step - loss: 0.0600 - acc: 0.9820 - val_loss: 0.0407 - val_acc: 0.9883\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 66s 1ms/step - loss: 0.0491 - acc: 0.9850 - val_loss: 0.0411 - val_acc: 0.9886\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 67s 1ms/step - loss: 0.0431 - acc: 0.9865 - val_loss: 0.0389 - val_acc: 0.9894\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 66s 1ms/step - loss: 0.0398 - acc: 0.9879 - val_loss: 0.0387 - val_acc: 0.9897\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 67s 1ms/step - loss: 0.0363 - acc: 0.9887 - val_loss: 0.0381 - val_acc: 0.9890\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 70s 1ms/step - loss: 0.0328 - acc: 0.9900 - val_loss: 0.0425 - val_acc: 0.9882\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 67s 1ms/step - loss: 0.0290 - acc: 0.9911 - val_loss: 0.0398 - val_acc: 0.9899\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 67s 1ms/step - loss: 0.0282 - acc: 0.9909 - val_loss: 0.0417 - val_acc: 0.9873\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 68s 1ms/step - loss: 0.0273 - acc: 0.9914 - val_loss: 0.0393 - val_acc: 0.9895\n",
      "Test loss: 0.03151901719397556\n",
      "Test accuracy: 0.9908\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=1/5.)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model\n",
    "#### Extra Credit Part 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/30\n",
      "48000/48000 [==============================] - 146s 3ms/step - loss: 0.0896 - acc: 0.9731 - val_loss: 0.0473 - val_acc: 0.9851\n",
      "Epoch 2/30\n",
      "48000/48000 [==============================] - 148s 3ms/step - loss: 0.0304 - acc: 0.9909 - val_loss: 0.0456 - val_acc: 0.9856\n",
      "Epoch 3/30\n",
      "48000/48000 [==============================] - 145s 3ms/step - loss: 0.0211 - acc: 0.9936 - val_loss: 0.0304 - val_acc: 0.9906\n",
      "Epoch 4/30\n",
      "48000/48000 [==============================] - 143s 3ms/step - loss: 0.0141 - acc: 0.9956 - val_loss: 0.0278 - val_acc: 0.9911\n",
      "Epoch 5/30\n",
      "48000/48000 [==============================] - 145s 3ms/step - loss: 0.0091 - acc: 0.9973 - val_loss: 0.0280 - val_acc: 0.9927\n",
      "Epoch 6/30\n",
      "48000/48000 [==============================] - 145s 3ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0280 - val_acc: 0.9927\n",
      "Epoch 7/30\n",
      "48000/48000 [==============================] - 146s 3ms/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0270 - val_acc: 0.9928\n",
      "Epoch 8/30\n",
      "48000/48000 [==============================] - 146s 3ms/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.0300 - val_acc: 0.9913\n",
      "Epoch 9/30\n",
      "48000/48000 [==============================] - 143s 3ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0322 - val_acc: 0.9916\n",
      "Epoch 10/30\n",
      "48000/48000 [==============================] - 151s 3ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0267 - val_acc: 0.9929\n",
      "Epoch 11/30\n",
      "48000/48000 [==============================] - 150s 3ms/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0270 - val_acc: 0.9933\n",
      "Epoch 12/30\n",
      "48000/48000 [==============================] - 150s 3ms/step - loss: 9.8481e-04 - acc: 0.9998 - val_loss: 0.0229 - val_acc: 0.9941\n",
      "Epoch 13/30\n",
      "48000/48000 [==============================] - 145s 3ms/step - loss: 7.7362e-04 - acc: 0.9999 - val_loss: 0.0228 - val_acc: 0.9944\n",
      "Epoch 14/30\n",
      "48000/48000 [==============================] - 150s 3ms/step - loss: 4.2536e-04 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 0.9945\n",
      "Epoch 15/30\n",
      "48000/48000 [==============================] - 148s 3ms/step - loss: 3.4182e-04 - acc: 1.0000 - val_loss: 0.0216 - val_acc: 0.9946\n",
      "Epoch 16/30\n",
      "48000/48000 [==============================] - 149s 3ms/step - loss: 5.1495e-04 - acc: 0.9999 - val_loss: 0.0237 - val_acc: 0.9937\n",
      "Epoch 17/30\n",
      "48000/48000 [==============================] - 150s 3ms/step - loss: 2.4891e-04 - acc: 1.0000 - val_loss: 0.0252 - val_acc: 0.9941\n",
      "Epoch 18/30\n",
      "48000/48000 [==============================] - 151s 3ms/step - loss: 1.9090e-04 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 0.9947\n",
      "Epoch 19/30\n",
      "48000/48000 [==============================] - 150s 3ms/step - loss: 1.7324e-04 - acc: 1.0000 - val_loss: 0.0244 - val_acc: 0.9942\n",
      "Epoch 20/30\n",
      "48000/48000 [==============================] - 151s 3ms/step - loss: 1.6172e-04 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 0.9942\n",
      "Epoch 21/30\n",
      "48000/48000 [==============================] - 153s 3ms/step - loss: 1.6908e-04 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 0.9947\n",
      "Epoch 22/30\n",
      "48000/48000 [==============================] - 145s 3ms/step - loss: 9.7433e-05 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 0.9947\n",
      "Epoch 23/30\n",
      "48000/48000 [==============================] - 146s 3ms/step - loss: 1.0482e-04 - acc: 1.0000 - val_loss: 0.0240 - val_acc: 0.9949\n",
      "Epoch 24/30\n",
      "48000/48000 [==============================] - 149s 3ms/step - loss: 9.4146e-05 - acc: 1.0000 - val_loss: 0.0242 - val_acc: 0.9943\n",
      "Epoch 25/30\n",
      "48000/48000 [==============================] - 154s 3ms/step - loss: 8.1065e-05 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 0.9950\n",
      "Epoch 26/30\n",
      "48000/48000 [==============================] - 146s 3ms/step - loss: 8.8605e-05 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 0.9949\n",
      "Epoch 27/30\n",
      "48000/48000 [==============================] - 147s 3ms/step - loss: 6.0739e-05 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 0.9952\n",
      "Epoch 28/30\n",
      "48000/48000 [==============================] - 147s 3ms/step - loss: 5.1939e-05 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 0.9951\n",
      "Epoch 29/30\n",
      "48000/48000 [==============================] - 146s 3ms/step - loss: 6.4268e-05 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 0.9947\n",
      "Epoch 30/30\n",
      "48000/48000 [==============================] - 145s 3ms/step - loss: 5.2817e-05 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 0.9947\n",
      "Test loss: 0.01788235190976543\n",
      "Test accuracy: 0.9955\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten,  Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "np.random.seed(2294)\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 30\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "# We added two additional Conv2D layers and BatchNormalization after each\n",
    "# layer\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10))\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=1/5.)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the test accuracy for our final model is 99.55%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
